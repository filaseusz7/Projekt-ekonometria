---
title: "Hiszpańskie Wina"
author: "Patryk Góreczny, Kamil Husak, Mateusz Filas"
date: '2022-05-12'
output: html_document
---


knitr::opts_chunk$set(echo = TRUE)
```{r eval=FALSE, include=FALSE}
install.packages('tidyverse')
install.packages('corrplot')
install.packages('lmtest')
install.packages('moments')
install.packages('rcompanion')
install.packages('strucchange')
```
```{r setup, include=FALSE}
# library(tidyverse)
library(dplyr)
library(ggplot2)
library(corrplot)
library(lmtest)
library(moments)
library(strucchange)
#library(rcompanion)
```
# •	Przedstawienie zagadnienia, przedstawienie danych

Ramka danych, którą będziemy analizować zawiera 7500 różnych czerwonych win pochodzenia Hiszpaśkiego, które opisane są przez jedenaście cech takich jak np. cena, region, winiarnia. Dane zostały zebrane za pomocą web scrapingu z różnych źródeł (od stron specjalizujących się w winach po supermarkety).

Informacje o cechach:

1. **winery** - nazwa winiarni

2. **wine** - nazwa wina

3. **year** - rok, w którym zebrano winogrona

4. **rating** - średnia ocena wina przyznana przez
użytkowników

5. **num_reviews** - liczba użytkowników, która oceniła wino

6. **country** - kraj pochodzenia wina

7. **region** - region, z którego pochodzi wino

8. **price** - cena wina w €

9. **typ** - typ wina

10. **body** - smak wina definiowany jako bogactwo i waga wina w ustach

11. **acidity** - ocena kwasowości wina


**Źródło danych** - [kaggle.com](https://www.kaggle.com/datasets/fedesoriano/spanish-wine-quality-dataset?fbclid=IwAR0PPTKB_U7lC_qTS9a6b1iytN-33YwvL6CfxyjrEDLl09JlKwgXAvRulUw)


Przedstawienie danych za pomocą funkcji `summary`.
```{r}
dane <- read.csv("wines_SPA.csv")
summary(dane)
```


```{r}
win <- dane %>% count(winery) %>%
  top_n(50)
hist(win$n, breaks = 30)

```

- Możemy zauważyć, że większość winiarni posiada tylko nieznaczną część wszystkich win

Ta sama sytuacja pojawia się w przypadku:

- regionów
```{r}
dane %>% count(region) %>%
  top_n(30)
```
- typów wina
```{r}
dane %>% count(type) %>%
  top_n(30)
```
- samych win
```{r}
dane %>% count(wine) %>%
  top_n(30)
```




Kilka wykresów obrazujących inne problemy z naszymi danymi

```{r}
ggplot(dane, aes(price)) +
  geom_density() +
  labs(title = "Rozkład cen poszczególnych win", x = "cena", y = "") +
  theme_light()
```
- Rozkład gęstości cen win uwidacznia bardzo długi ogon
```{r}
dane0 <- dane %>% filter(price <= 150)
ggplot(dane0, aes(price)) +
  geom_density() +
  labs(title = "Rozkład cen poszczególnych win", x = "cena", y = "") +
  theme_light()
```

```{r}
dane1 <- dane %>% filter(price <= 80)
nrow(dane1)/nrow(dane)
```
- Zauważmy, że ponad 90% win kosztuje mniej niż 80€

Teraz zobaczmy jak wygląda rozkład liczby ocen win
```{r}
ggplot(dane, aes(num_reviews)) +
  geom_density() +
  labs(title = "Rozkład liczby ocen poszczególnych win", x = "liczba ocen", y = "") +
  theme_light()
```

- W tym przypadku również możemy zaobserwować podobną sytuację
```{r}
dane2 <- dane %>% filter(num_reviews <= 1000)
ggplot(dane2, aes(num_reviews)) +
  geom_density() +
  labs(title = "Rozkład liczby ocen poszczególnych win", x = "liczba ocen", y = "") +
  theme_light()
```

```{r}
dane3 <- dane %>% filter(num_reviews <= 800, num_reviews >= 100)
nrow(dane3)/nrow(dane)
```
- Liczba ocen ponad 84% win mieści się w przedziale od 100 do 800.

Możemy również zobaczyć, że kolumna `body` zawiera wartości od 2 do 5, z czego wartości równych 2 jest zdecydowanie za mało, żeby brać je pod uwagę.
```{r}
dane %>% count(body)
```

Tak samo jest w przypadku kolumny `acidity`, gdzie ilość pól z wartością '1' jest wynosi zaledwie 4.
```{r}
dane %>% count(acidity)
```



# •	Transformacje wykonane na danych (np. usuwanie braków, usuwanie zmiennych, modyfikacja)

Wczytujemy dane z pliku wines_SPA
Wstępna analiza naszych danych pokazała kilka rzeczy, które należy poprawić. Po pierwsze usuwamy zbędną kolumnę `country`, ponieważ występuje w niej jedna i ta sama wartość - Espana. Następnie musimy usunąć 'ogon' dla cen win oraz liczby ocen, aby nie zakłamywały wyników. Usuwamy też wiersze, w których nie ma informacji o roku produkcji, a także te wiersze, w których `body` = 2 oraz `acidity` = 1, ponieważ wartości te przyjmowane są zbyt rzadko, by brać je pod uwagę. Poza tym usuwamy wszystkie wiersze, w których występują jakiekolwiek braki danych.
Zdecydowaliśmy się jeszcze na usunięcie kolumny zawierającej informacje o nazwie wina.

```{r}
dane <- read.csv('wines_SPA.csv') 
dane <- select(dane, -country, -wine)
dane <- dane[!(dane$price>80),]
dane <- dane[!(dane$num_reviews<100),]
dane <- dane[!(dane$num_reviews>800),]
dane <- dane[!(dane$year=='N.V.'),]
dane <- dane[!(dane$year==''),]
dane <- dane[complete.cases(dane),]
dane <- dane[!(dane$body==2),]
dane <- dane[!(dane$acidity==1),]
```

Następnym etapem jest czyszczenie danych, tzn., że w przypadku niektórych kolumn mamy bardzo dużo różnych wartości, które występują bardzo małą ilość razy i to właśnie te wartości będą sklasyfikowane jako 'Inne'.

- Czyszczenie winiarni

Jeśli dana winiarnia występuje mniej niż 13 razy to zaliczamy ją do 'Innych'
```{r}
winiarnie <- data.frame(unique(dane$winery))
for(i in 1:length(unique(dane$winery))){
  winiarnie[i,2] <- sum(dane$winery==winiarnie[i, 1])
}
for(i in 1:length(winiarnie[,1])){
  for(j in 1:length(dane$winery))
  {
    if(winiarnie$unique.dane.winery[i] == dane$winery[j])
    {
      if(winiarnie$V2[i] < 13){
        dane$winery[j] <- 'Inne'
      }
    }
  }
}

winiarnie <- data.frame(unique(dane$winery))
for(i in 1:length(unique(dane$winery))){
  winiarnie[i,2] <- sum(dane$winery==winiarnie[i, 1])
}
```

- Czyszczenie regionów

Jeśli dany region występuje mniej niż 20 razy to zaliczamy go do 'Innych'
```{r}
regiony <- data.frame(unique(dane$region))
for(i in 1:length(unique(dane$region))){
 regiony[i,2] <- sum(dane$region==regiony[i, 1])
}
for(i in 1:length(regiony[,1])){
  for(j in 1:length(dane$region))
  {
    if(regiony$unique.dane.region[i] == dane$region[j])
    {
      if(regiony$V2[i] < 20){
        dane$region[j] <- 'Inne'
      }
    }
  }
}

regiony <- data.frame(unique(dane$region))
for(i in 1:length(unique(dane$region))){
  regiony[i,2] <- sum(dane$region==regiony[i, 1])
}
```

- Czyszczenie typów win

Jeśli dany typ wina występuje mniej niż 70 razy to zaliczamy go do 'Innych'
```{r}
typy <- data.frame(unique(dane$type))
for(i in 1:length(unique(dane$type))){
  typy[i,2] <- sum(dane$type==typy[i, 1])
}
for(i in 1:length(typy[,1])){
  for(j in 1:length(dane$type))
  {
    if(typy$unique.dane.type[i] == dane$type[j])
    {
      if(typy$V2[i] < 70){
        dane$type[j] <- 'Inne'
      }
    }
  }
}

typy <- data.frame(unique(dane$type))
for(i in 1:length(unique(dane$type))){
  typy[i,2] <- sum(dane$type==typy[i, 1])
}
```


# •	Podział na zbiór treningowy i testowy

Zmieniamy typ naszch zmiennych `winery`, `region`, `body`, `acidity` oraz `type` na factor. Następnie dzielimy nasz zbiór na zbiór treningowy (80%) i zbiór testowy (20%).

```{r}
dane <- dane %>%
  mutate(across(c("winery", "region", "body", "acidity", "type"), as.factor))
summary(dane)

rows <- 1:nrow(dane)
sample_train <- sample(rows, size = round(0.8 * nrow(dane)))
train <- dane %>% slice(sample_train)
test <- dane %>% slice(-sample_train)
```

# •	Dobór zmiennych
Przyjmujemy że zmienną objaśnianą w naszym modelu jest cena, a zmiennymi objaśniającymi są wszystkie pozostałe zmienne.
```{r}
model <- lm(price ~ .-region-type, data=train)
summary(model)
```

```{r}
uniqRegion <- unique(dane$region)
uniqType <- unique(dane$type)
 
df_type_region <- matrix(0,length(uniqRegion),length(uniqType))
df_type_region <- data.frame(df_type_region)
for(i in 1:length(uniqRegion)){
  for(j in 1:length(uniqType)){
     for(k in 1:length(dane$region)){
      if(uniqRegion[i] == dane$region[k])
      {
         if(uniqType[j] == dane$type[k]){
          df_type_region[i,j] <- df_type_region[i,j] + 1
         }
     }
            }
   }
 }
colnames(df_type_region) <- uniqType
rownames(df_type_region) <- uniqRegion
```

```{r}
uniqWinery <- unique(dane$winery)
uniqType <- unique(dane$type)
 
df_type_winery <- matrix(0,length(uniqWinery),length(uniqType))
df_type_winery <- data.frame(df_type_winery)
for(i in 1:length(uniqWinery)){
  for(j in 1:length(uniqType)){
     for(k in 1:length(dane$winery)){
      if(uniqWinery[i] == dane$winery[k])
      {
         if(uniqType[j] == dane$type[k]){
          df_type_winery[i,j] <- df_type_winery[i,j] + 1
         }
     }
            }
   }
 }
colnames(df_type_winery) <- uniqType
rownames(df_type_winery) <- uniqWinery
```

Następnie, w celu stwierdzenia, która z trzech zmiennych kategorycznych (region, typ, winiarnia) jest najbardziej skorelowana ze zmienną objaśnianą, policzymy wspólczynniki V-Cramera. Robimy to, ponieważ te trzy zmienne wyszły nam współliniowe, tzn. przenoszą tą samą informację i nie są nam wszystkie potrzebne.

- region-cena
```{r}
region_cena <- matrix(0,nrow=11,ncol=11)
sumRi <- c()
for(k in 1:11){
  for(j in 1:11){
    sumRi[j] = 0
    for(i in 1:length(dane[,1])){
      if(j==11){
        if(dane$region[i]==regiony$unique.dane.region.[k] & dane$price[i]>=7*j)
          region_cena[k,j]=region_cena[k,j]+1
      }
      if(j<11){
        if(dane$region[i]==regiony$unique.dane.region.[k] & dane$price[i]<7*j & dane$price[i]>=7*j-7  )
          region_cena[k,j]=region_cena[k,j]+1}
    }
  }}
```
Powstaje nam taka macierz:
```{r}
region_cena
```
Wspólczynnik V-Cramera dla region-cena wynosi:
```{r}
#cramerV(region_cena)
```


- typ-cena
```{r}
typ_cena <- matrix(0,nrow=9,ncol=9)
sumTyp <- c()
for(k in 1:9){
  for(j in 1:9){
    sumTyp[j] = 0
    for(i in 1:length(dane[,1])){
      if(j==9){
        if(dane$type[i]==typy$unique.dane.type.[k] & dane$price[i]>=8*j)
          typ_cena[k,j]=typ_cena[k,j]+1
      }
      if(j<9){
        if(dane$type[i]==typy$unique.dane.type.[k] & dane$price[i]<8*j & dane$price[i]>=8*j-8  )
          typ_cena[k,j]=typ_cena[k,j]+1}
    }
  }}
```
Powstaje nam taka macierz:
```{r}
typ_cena
```
Współczynnik V-Cramera dla typ-cena wynosi:
```{r}
#cramerV(typ_cena)
```

- winiarnia-cena
```{r}
winiarnia_cena <- matrix(0,nrow=23,ncol=23)
sumWiniarnia <- c()
for(k in 1:23){
  for(j in 1:23){
    sumTyp[j] = 0
    for(i in 1:length(dane[,1])){
      if(j==23){
        if(dane$winery[i]==winiarnie$unique.dane.winery.[k] & dane$price[i]>=7+3*j)
          winiarnia_cena[k,j]=winiarnia_cena[k,j]+1
      }
      if(j<23&j>1){
        if(dane$winery[i]==winiarnie$unique.dane.winery.[k] & dane$price[i]<7+3*(j-1) & dane$price[i]>=3*(j-1)-3+7  )
          winiarnia_cena[k,j]=winiarnia_cena[k,j]+1
      }
      if(j==1){
        if(dane$winery[i]==winiarnie$unique.dane.winery.[k] & dane$price[i]<7)
          winiarnia_cena[k,j]=winiarnia_cena[k,j]+1}
    }
  }}
```
Powstaje nam taka macierz:
```{r}
winiarnia_cena
```

Wspólczynnik V-Cramera dla winiarnia-cena wynosi:
```{r}
# cramerV(winiarnia_cena)
```
Sprawdzamy, dla którego zestawu współczynnik V-Cramera jest największy
```{r}
#cramerV(typ_cena)
#cramerV(region_cena)
#cramerV(winiarnia_cena)
```
Jak się okazało, największy współczynnik wychodzi dla winiarnia-cena i wynosi on 0.72.

```{r}
model <- lm(price ~ .-region-type, data=traint)
summary(model)
```
# •	Postać modelu (wzór).
# •	Diagnostyka (i próba poprawy modelu, jeśli wystąpiły problemy)

Teraz, żeby zobaczyć czy występuje autokorelacja użyjemy testu Durbina-Watson
```{r}
mean(model$residuals)

dwtest(model)
```
Test wykazał, że nie ma autokorelacji

- heteroskedastyczność
```{r}
bptest(model) # studentized Breusch Pagan test

gqtest(model, point = 0.7, order.by = ~price, data = train) # Goldfield-Quandt test
```
- normalność reszt
```{r}
shapiro.test(model$residuals)

skewness(train$price)
kurtosis(train$price)
hist(train$price)
plot(train$num_reviews, train$price)
abline(lm(train$price~train$num_reviews), col='blue')
plot(train$rating, train$price)
abline(lm(train$price~train$rating), col='blue')
plot(train$price, model$residuals)
hist(model$residuals)
traint <- train %>%
  arrange(price)
traint %>%
  filter(price < 45) 
sctest(price ~ . - type - region,data=traint, type='Chow', point=2623)
```
 
# •	Prognoza na zbiór testowy i błędy prognozy
```{r}
prediction <- predict(model, newdata = test, se.fit = T)
ex_post <- test$price - prediction$fit
MAE <- mean(abs(ex_post)) # mean absolute error
RMSE <- mean(sqrt(ex_post^2)) # root mean squared error
MAPE <- mean(abs(((test$price - prediction$fit)/test$price)))  # mean absolute percentage error
```


# •	Podsumowanie (w tym interpretacja)
